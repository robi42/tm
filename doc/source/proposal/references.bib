@book{Manning2008,
  abstract = {Class-tested and coherent, this groundbreaking new textbook teaches web-era information retrieval,  including web search and the related areas of text classification and text clustering from basic concepts. Written   from a computer science perspective by three leading experts in the field, it gives an up-to-date treatment of all  aspects of the design and implementation of systems for gathering, indexing, and searching documents; methods for  evaluating systems; and an introduction to the use of machine learning methods on text collections. All the important  ideas are explained using examples and figures, making it perfect for introductory courses in information retrieval  for advanced undergraduates and graduate students in computer science. Based on feedback from extensive classroom  experience, the book has been carefully structured in order to make teaching more natural and effective. Although  originally designed as the primary text for a graduate or advanced undergraduate course in information retrieval, the  book will also create a buzz for researchers and professionals alike.},
  archivePrefix = {arXiv},
  arxivId = {0521865719 9780521865715},
  author = {Manning, Christopher D. and Raghavan, Prabhakar and Sch\"{u}tze, Hinrich},
  booktitle = {Online},
  doi = {10.1109/LPT.2009.2020494},
  eprint = {0521865719 9780521865715},
  isbn = {0521865719},
  issn = {13864564},
  pages = {496},
  pmid = {10575050},
  publisher = {Cambridge University Press},
  title = {{Introduction to Information Retrieval}},
  url = {http://nlp.stanford.edu/IR-book/},
  volume = {1},
  year = {2008}
}

@book{Norman2002,
  abstract = {Even the smartest among us can feel inept as we fail to figure out which switch turns on which light or stove burner, or whether to push, pull, or slide a door. The fault lies in product designs that ignore the needs of users and the principles of cognitive psychology. A bestseller in the United States, this classic work on the cognitive aspects of design contains examples of both good and bad design and simple rules that designers can use to improve the usability of objects as diverse as cars, computers, doors, and telephones.-From publisher description.},
  author = {Norman, Donald A},
  booktitle = {Human Factors and Ergonomics in Manufacturing},
  chapter = {7},
  doi = {10.1002/hfm.20127},
  isbn = {0465067107},
  issn = {03071766},
  pages = {272},
  pmid = {13182255},
  publisher = {Basic Books},
  title = {{The Design of Everyday Things}},
  url = {http://ucdwiki.chuank.com/uploads/Main/UCDReading\_wk5.pdf},
  year = {2002}
}

@book{Aigner2011,
  title = {Visualization of Time-Oriented Data},
  series = {Human-Computer Interaction},
  year = {2011},
  pages = {286},
  publisher = {Springer Verlag},
  organization = {Springer Verlag},
  edition = {1st},
  location = {London, UK},
  abstract = {<p>Time is an exceptional dimension that is common to many application domains such as medicine, engineering, business, science, biography, history, planning, or project management. Understanding time-oriented data enables us to learn from the past in order to predict, plan, and build the future. Due to the distinct characteristics of time, appropriate visual and analytical methods are required to explore and analyze them.</p>
<div class="springerHTML">
  <p>This book starts with an introduction to visualization and a number of historical examples of visual representations. At its core, the book presents and discusses a systematic view of the visualization of time-oriented data. This view is structured along three key questions. While the aspects of time and associated data describe <i>what</i> is being visualized, user tasks are related to the question <i>why</i> something is visualized. These characteristics and tasks determine <i>how </i>the visualization is to be designed. To support visual exploration, interaction techniques and analytical methods are required as well, which are discussed in separate chapters. The concepts explained in this book are illustrated with numerous examples.</p>
  <p>A large part of this book is devoted to a structured survey of existing techniques for visualizing time and time-oriented data. Overall, 101 different visualization techniques are presented on a per-page basis; each of these self-contained descriptions is accompanied by an illustration and corresponding references.\&nbsp; This survey serves as a reference for scientists conducting related research as well as for practitioners seeking information on how their time-oriented data can best be visualized in order to gain valuable insights.</p>
</div>
},
  keywords = {Analysis, Computer-Generated Visual Representations, Human-computer Interaction, Time-Oriented Data, User, Visual analytics, Visualization},
  isbn = {978-0-85729-078-6},
  doi = {10.1007/978-0-85729-079-3},
  url = {http://www.timeviz.net},
  author = {Aigner, Wolfgang and Miksch, Silvia and Schumann, H. and Tominski, C.}
}

@book{Witten2011,
  abstract = {Like the popular second edition, Data Mining: Practical Machine Learning Tools and Techniques offers a thorough grounding in machine learning concepts as well as practical advice on applying machine learning tools and techniques in real-world data mining situations. Inside, you'll learn all you need to know about preparing inputs, interpreting outputs, evaluating results, and the algorithmic methods at the heart of successful data mining?including both tried-and-true techniques of today as well as methods at the leading edge of contemporary research. Complementing the book is a fully functional platform-independent open source Weka software for machine learning, available for free download. The book is a major revision of the second edition that appeared in 2005. While the basic core remains the same, it has been updated to reflect the changes that have taken place over the last four or five years. The highlights for the updated new edition include completely revised technique sections; new chapter on Data Transformations, new chapter on Ensemble Learning, new chapter on Massive Data Sets, a new ?book release? version of the popular Weka machine learning open source software (developed by the authors and specific to the Third Edition); new material on ?multi-instance learning?; new information on ranking the classification, plus comprehensive updates and modernization throughout. All in all, approximately 100 pages of new material. Thorough grounding in machine learning concepts as well as practical advice on applying the tools and techniques Algorithmic methods at the heart of successful data mining?including tired and true methods as well as leading edge methods Performance improvement techniques that work by transforming the input or output Downloadable Weka, a collection of machine learning algorithms for data mining tasks, including tools for data pre-processing, classification, regression, clustering, association rules, and visualization?in an updated, interactive interface.},
  author = {Witten, Ian H and Frank, Eibe and Hall, Mark A},
  isbn = {9780123748560},
  edition = {3rd},
  number = {2},
  pages = {664},
  publisher = {Morgan Kaufmann},
  series = {Morgan Kaufmann series in data management systems},
  title = {{Data Mining: Practical Machine Learning Tools and Techniques}},
  url = {http://www.amazon.com/Data-Mining-Practical-Techniques-Management/dp/0123748569},
  year = {2011}
}

@book{dasu2003exploratory,
  author = {Dasu, T and Johnson, T},
  isbn = {9780471268512},
  publisher = {Wiley},
  series = {Wiley Series in Probability and Statistics},
  title = {{Exploratory Data Mining and Data Cleaning}},
  url = {http://books.google.at/books?id=2OWJVkevamQC},
year = {2003}
}

@article{Thomas2006,
  abstract = {Researchers have made significant progress in disciplines such as scientific and information visualization, statistically based exploratory and confirmatory analysis, data and knowledge representations, and perceptual and cognitive sciences. Although some research is being done in this area, the pace at which new technologies and technical talents are becoming available is far too slow to meet the urgent need. National Visualization and Analytics Center's goal is to advance the state of the science to enable analysts to detect the expected and discover the unexpected from massive and dynamic information streams and databases consisting of data of multiple types and from multiple sources, even though the data are often conflicting and incomplete. Visual analytics is a multidisciplinary field that includes the following focus areas: (i) analytical reasoning techniques, (ii) visual representations and interaction techniques, (iii) data representations and transformations, (iv) techniques to support production, presentation, and dissemination of analytical results. The R\&amp;D agenda for visual analytics addresses technical needs for each of these focus areas, as well as recommendations for speeding the movement of promising technologies into practice. This article provides only the concise summary of the R\&amp;D agenda. We encourage reading, discussion, and debate as well as active innovation toward the agenda for visual analysis.},
  author = {Thomas, James J and Cook, Kristin A},
  doi = {10.1109/MCG.2006.5},
  institution = {Pacific Northwest National Laboratory, USA. jim.thomas@pnl.gov},
  issn = {02721716},
  journal = {IEEE Computer Graphics and Applications},
  number = {1},
  pages = {10--13},
  pmid = {16463473},
  publisher = {IEEE Computer Society Press},
  title = {{A Visual Analytics Agenda}},
  url = {http://www.ncbi.nlm.nih.gov/pubmed/16463473},
  volume = {26},
  year = {2006}
}

@article{Raman2001a,
  abstract = {Cleaning data of errors in structure and content is important for data warehousing and integration. Current solutions for data cleaning involve many iterations of data auditing to find errors, and long-running transformations to fix them. Users need to endure long waits, and often write complex transformation scripts. We present Potters Wheel, an interactive data cleaning system that tightly integrates transformation and discrepancy detection. Users gradually build transformations to clean the data by adding or undoing transforms on a spreadsheet-like interface; the effect of a transform is shown at once on records visible on screen. These transforms are specified either through simple graphical operations, or by showing the desired effects on example data values. In the background, PottersWheel automatically infers structures for data values in terms of user-defined domains, and accordingly checks for constraint violations. Thus users can gradually build a transformation as discrepancies are found, and clean the data without writing complex programs or enduring long delays.},
  author = {Raman, Vijayshankar and Hellerstein, Joseph M},
  doi = {10.1.1.39.2790},
  editor = {Apers, Peter M G and Atzeni, Paolo and Ceri, Stefano and Paraboschi, Stefano and Ramamohanarao, Kotagiri and Snodgrass, Richard T},
  isbn = {1558608044},
  issn = {10477349},
  journal = {Data Base},
  pages = {381--390},
  publisher = {Morgan Kaufmann},
  title = {{Potter's Wheel: An Interactive Data Cleaning System}},
  url = {http://www.vldb.org/conf/2001/P381.pdf},
  volume = {01},
  year = {2001}
}

@article{Kandel2011a,
  abstract = {Though data analysis tools continue to improve, analysts still expend an inordinate amount of time and effort manipulating data and assessing data quality issues. Such "data wrangling" regularly involves reformatting data values or layout, correcting erroneous or missing values, and integrating multiple data sources. These transforms are often difficult to specify and difficult to reuse across analysis tasks, teams, and tools. In response, we introduce Wrangler, an interactive system for creating data transformations. Wrangler combines direct manipulation of visualized data with automatic inference of relevant transforms, enabling analysts to iteratively explore the space of applicable operations and preview their effects. Wrangler leverages semantic data types (e.g., geographic locations, dates, classification codes) to aid validation and type conversion. Interactive histories support review, refinement, and annotation of transformation scripts. User study results show that Wrangler significantly reduces specification time and promotes the use of robust, auditable transforms instead of manual editing.},
  author = {Kandel, Sean and Paepcke, Andreas and Hellerstein, Joseph and Heer, Jeffrey},
  doi = {10.1145/1978942.1979444},
  institution = {ACM},
  isbn = {9781450302678},
  journal = {Human Factors},
  pages = {3363--3372},
  publisher = {ACM Press},
  title = {{Wrangler: Interactive Visual Specification of Data Transformation Scripts}},
  url = {http://vis.stanford.edu/papers/wrangler},
  year = {2011}
}

@inproceedings{Dasu:2002:MDS:564691.564719,
  address = {New York, NY, USA},
  author = {Dasu, Tamraparni and Johnson, Theodore and Muthukrishnan, S and Shkapenyuk, Vladislav},
  booktitle = {Proceedings of the 2002 ACM SIGMOD international conference on Management of Data},
  doi = {10.1145/564691.564719},
  isbn = {1-58113-497-5},
  pages = {240--251},
  publisher = {ACM},
  series = {SIGMOD '02},
  title = {{Mining Database Structure; Or, How to Build a Data Quality Browser}},
  url = {http://doi.acm.org/10.1145/564691.564719},
  year = {2002}
}

@misc{hellerstein_quantitative,
  author = {Hellerstein, Joseph M},
  howpublished = {United Nations Economic Commission for Europe (UNECE)},
  keywords = {cidr2011,tkde,uist2010},
  title = {{Quantitative Data Cleaning for Large Databases}},
  year = {2008}
}

@misc{web:OpenRefine,
  author = {{OpenRefine Git Repo}},
  title = {https://github.com/OpenRefine/OpenRefine},
  note = {Accessed: 2012-11-03}
}
